{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uo0JP7a5uFp7"
   },
   "source": [
    "# **Notebook to uncover the key parts of ASR**\n",
    "\n",
    "This tutorial will walk you through all the modules needed to implement an offline **end-to-end attention-based speech recognizer** on Speechbrain.\n",
    "\n",
    "For simplicity, we are not training any model, but rather using the models (AM/LM/Tokenizer) available from huggingface hub. The models are trained in an open-source dataset called [librispeech](https://www.openslr.org/12/) with 960 hours of train data.\n",
    "\n",
    "In this tutorial, we will refer to the code in ```NLP_Summer_School-2021_Speech_Tutorial/ASR/LibriSpeech/{ASR,LM,Tokenizer}```. \n",
    "You could follow up a more detailed Colab Notebook about training ASR from Scratch: [Colab Notebook - Train from Scratch](https://colab.research.google.com/drive/1aFgzrUv3udM_gNJNUoLaHIm78QHtxdIz?usp=sharing)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eWpl9xgAIXKE"
   },
   "source": [
    "## **Which modules are we covering today?**\n",
    "\n",
    "In order to train the LM and AM, you would need to prepare LibriSpeech folder + download all the required material. Training could take days in cluster with several GPUs. \n",
    "\n",
    "0. **Data preparation**.\n",
    "For this tutorial we won't need any data preparation step, because we will take adavantage of the Speechbrain class `EncoderDecoderASR`; which could apply inference in one simple `wav` file.  \n",
    "\n",
    "1. **Tokenizer**.\n",
    "The tokenizer decides which basic units are allocated during ASR training/infernce (e.g, characters, phonemes, sub-words, words).\n",
    "\n",
    "```\n",
    "cd NLP_Summer_School-2021_Speech_Tutorial/ASR/LibriSpeech/Tokenizer\n",
    "python train.py tokenizer.yaml\n",
    "```\n",
    "\n",
    "2. **The language model**.\n",
    "After that, the language model could be trained (we just used during inference). In this example, however, we don't train it (rather download a pre-trained version)\n",
    "\n",
    "We need an additional Python (Huggingface) library: `datasets`\n",
    "```\n",
    "pip install datasets\n",
    "cd NLP_Summer_School-2021_Speech_Tutorial/ASR/LibriSpeech/LM\n",
    "python train.py hparams/transformer.yaml\n",
    "```\n",
    "\n",
    "3. **Automatic speech recognizer - Speech-to-text system**.\n",
    "At this point, we are ready to train our speech recognizer. In this tutorial, we will use the CRDNN model with an autoregressive GRU decoder. An attention mechanism is employed between encoding and decoder. The final sequence of words is retrieved with beamsearch coupled with the Transformer LM fetched in the previous stes:\n",
    "```\n",
    "cd NLP_Summer_School-2021_Speech_Tutorial/ASR/LibriSpeech/ASR/transformer\n",
    "python train.py hparams/transformer.yaml\n",
    "```\n",
    "\n",
    "4. **Use the speech recognizer (inference)**:\n",
    "After training, we can use the speech recognizer for inference. We will use the `EncoderDecoderASR` class available in SpeechBrain to make inference.\n",
    "\n",
    "(Most of this tutorial is based on the [ASRfromScratch](https://colab.research.google.com/drive/1aFgzrUv3udM_gNJNUoLaHIm78QHtxdIz?usp=sharing) Google Colab! Thanks!)\n",
    "\n",
    "We will go through each of these "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rDgNu_b8k6qD"
   },
   "source": [
    "## **Step 0: Prepare your data** \n",
    "\n",
    "**!! You don't need to do anything here for the NLP summer school speech Tutorial. In case you'd like to continue training your own ASR engine, you could follow the notebooks' links at the end of this one.**\n",
    "\n",
    "The goal of data preparation is to create the data manifest files. \n",
    "These files tell SpeechBrain where to find the audio data and their corresponding transcriptions. They are text files written in the popular CSV and JSON formats.\n",
    "\n",
    "### **Data manifest files**\n",
    "Let's take a look into how a data manifest file in JSON format looks like:\n",
    "\n",
    "\n",
    "```json\n",
    "{\n",
    "  \"1867-154075-0032\": {\n",
    "    \"wav\": \"{data_root}/LibriSpeech/train-clean-5/1867/154075/1867-154075-0032.flac\",\n",
    "    \"length\": 16.09,\n",
    "    \"words\": \"AND HE BRUSHED A HAND ACROSS HIS FOREHEAD AND WAS INSTANTLY HIMSELF CALM AND COOL VERY WELL THEN IT SEEMS I'VE MADE AN ASS OF MYSELF BUT I'LL TRY TO MAKE UP FOR IT NOW WHAT ABOUT CAROLINE\"\n",
    "  },\n",
    "  \"1867-154075-0001\": {\n",
    "    \"wav\": \"{data_root}/LibriSpeech/train-clean-5/1867/154075/1867-154075-0001.flac\",\n",
    "    \"length\": 14.9,\n",
    "    \"words\": \"THAT DROPPED HIM INTO THE COAL BIN DID HE GET COAL DUST ON HIS SHOES RIGHT AND HE DIDN'T HAVE SENSE ENOUGH TO WIPE IT OFF AN AMATEUR A RANK AMATEUR I TOLD YOU SAID THE MAN OF THE SNEER WITH SATISFACTION\"\n",
    "  },\n",
    "}\n",
    "```\n",
    "As you can see, we have a hierarchical structure in which: \n",
    "\n",
    "- Key: **unique identifier** of the spoken sentence,\n",
    "- First item: **path of the speech recording**,\n",
    "- Second item: **length**, if we have a segments file we might need to change this, \n",
    "- Third item: **sequence of words** for the given train/test sample.\n",
    "\n",
    "### **Preparation Script**\n",
    "Every dataset is formatted in a different way. The script that parses your own dataset and creates the JSON or the CSV files is something that you are supposed to write. Most of the time, this is very straightforward. \n",
    "\n",
    "For the mini-librispeech dataset, for instance, we wrote this simple data preparation script called [mini_librispeech_prepare.py](https://github.com/speechbrain/speechbrain/blob/develop/templates/speech_recognition/mini_librispeech_prepare.py).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9To_-2fej2SA"
   },
   "source": [
    "## **Step 1: Tokenizer** \n",
    "An important decision to make when designing a speech recognizer concerns the basic tokens that our system has to predict (e.g, characters, phonemes, sub-words, words).\n",
    "\n",
    "### **Using characters as tokens**\n",
    "One way is to predict characters. In this case, we simply convert the sequence of words into its corresponding sequence of characters (using the space '_' as an additional character):\n",
    "\n",
    "`THE CITY OF BOGOTA IN COLOMBIA => ['T','H','E', '_', 'C','I','T','Y','_', 'O', 'F', '_, 'B','O','G','O','T','A','_','I','N','_','C','O','L','O','M','B','I''A']`\n",
    "\n",
    "Key information about using characters as tokens:\n",
    "+ Enough training data for each token, our system would need to predict between 20-30 tokens (depending on the language),\n",
    "+ Out system might generalize to words never seen during training.\n",
    "\n",
    "### **Using words as tokens**\n",
    "Why not predicting full words then? \n",
    "\n",
    "`THE CITY OF BOGOTA IN COLOMBIA => ['THE','CITY','OF','BOGOTA', 'IN', 'COLOMBIA']`\n",
    "\n",
    "Key information about using words as tokens:\n",
    "+ Output sequence is short (only words) and some symbols if defined.\n",
    "+ The system, however, cannot anymore generalize to new words \n",
    "\n",
    "### **Byte Pair Encoding (BPE)**\n",
    "What about something in between? \n",
    "This is what we are trying to do with BPE tokens. BPE is a simple technique inherited from data compression. The basic idea is to allocate tokens for the most frequent sequences of characters. For instance:\n",
    "\n",
    "`THE CITY OF BOGOTA IN COLOMBIA => ['▁TH', 'E', '▁C', 'I', 'TY', '▁OF', '▁BO', 'G', 'O', 'TA', '▁I', 'N', '▁C', 'O', 'L', 'OM', 'B', 'IA']`\n",
    "\n",
    "The [algorithm that finds these tokens](https://en.wikipedia.org/wiki/Byte_pair_encoding) is very simple: we start from the characters and we count how many times two consecutive characters are observed together. We allocate a token for the most frequent pair and we iterate over and over until a specified number of tokens is reached. For more information, you can take a look at [our tutorial on the tokenizers](https://colab.research.google.com/drive/12yE3myHSH-eUxzNM0-FLtEOhzdQoLYWe?usp=sharing).\n",
    "\n",
    "#### *How many BPE tokens should I use?*\n",
    "The number of tokens is one of the hyperparameters of your system.\n",
    "Its optimal value depends on the amount of speech data available. Just to give you an idea, for LibriSpeech (i.e., 1000 hours of sentences in English) a reasonable number of tokens ranges between 1k and 10k.\n",
    "\n",
    "### **Train a Tokenizer**\n",
    "SpeechBrain relies on the popular [SentencePiece](https://github.com/google/sentencepiece) for tokenization. To find the tokens to allocate (given the training transcriptions), run the following code:\n",
    "\n",
    "```\n",
    "cd NLP_Summer_School-2021_Speech_Tutorial/ASR/LibriSpeech/Tokenizer\n",
    "python train.py tokenizer.yaml\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Testing the Tokenizer fetched from Speechbrain (HuggingFace hub)**\n",
    "\n",
    "You should be able to fetch the models that you downloaded and then unzipped (they should be in `./pretrained_models/tokenizer.ckpt`)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchaudio\n",
    "\n",
    "import speechbrain as sb\n",
    "from speechbrain.pretrained import EncoderDecoderASR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "asr_model = EncoderDecoderASR.from_hparams(source=\"speechbrain/asr-transformer-transformerlm-librispeech\", savedir=\"pretrained_models/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tA4HMrnFJ33e",
    "outputId": "4936af97-e07a-4882-b511-bd89b86802b0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoded as pieces: ['▁THIS', '▁IS', '▁THE', '▁', 'N', 'L', 'P', '▁SUMMER', '▁SCHOOL', ',', '▁THANK', '▁YOU', '▁FOR', '▁ATTEND', 'ING', '▁IT']\n",
      "Encoded as ids: [44, 33, 3, 78, 36, 134, 102, 1321, 761, 0, 868, 24, 25, 1465, 13, 17]\n"
     ]
    }
   ],
   "source": [
    "# Modify the following phrase to check how the Tokenizer works:\n",
    "\n",
    "phrase = 'THIS IS THE NLP SUMMER SCHOOL, THANK YOU FOR ATTENDING IT'\n",
    "print(\"Encoded as pieces: {}\".format(asr_model.tokenizer.encode(phrase, out_type=str)))\n",
    "print(\"Encoded as ids: {}\".format(asr_model.tokenizer.encode_as_ids(phrase)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Tokenizer also assigns a unique index to each token. These indexes will correspond to the output of our neural networks for LM and ASR. It's important to keep that in mind (i.e., defining the number of outputs in the ASR/LM neural networks) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of different units in your Tokenizer is: 5000 units\n"
     ]
    }
   ],
   "source": [
    "# do you want to know the size of the Tokenizer? \n",
    "print(\"The number of different units in your Tokenizer is: {} units\".format(asr_model.tokenizer.vocab_size()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Version 0: ['▁T', 'H', 'IS', '▁', 'IS', '▁', 'TH', 'E', '▁', 'N', 'L', 'P', '▁S', 'UM', 'M', 'ER', '▁SCHOOL', ',', '▁', 'TH', 'AN', 'K', '▁YOU', '▁F', 'OR', '▁A', 'T', 'TEN', 'D', 'I', 'NG', '▁IT']\n",
      "Version 1: ['▁', 'T', 'HI', 'S', '▁', 'I', 'S', '▁', 'TH', 'E', '▁', 'N', 'L', 'P', '▁SUMMER', '▁SCHOOL', ',', '▁THAN', 'K', '▁YOU', '▁FOR', '▁AT', 'TEN', 'D', 'ING', '▁I', 'T']\n",
      "Version 2: ['▁T', 'HI', 'S', '▁I', 'S', '▁THE', '▁', 'N', 'L', 'P', '▁SU', 'M', 'M', 'E', 'R', '▁SCH', 'O', 'O', 'L', ',', '▁', 'T', 'HA', 'N', 'K', '▁YOU', '▁FOR', '▁', 'AT', 'TEN', 'D', 'ING', '▁IT']\n"
     ]
    }
   ],
   "source": [
    "# Nevertheles, there could be several ways how this phrase could be represented:\n",
    "for n in range(3):\n",
    "    print(\"Version {}: {}\".format(n,asr_model.tokenizer.encode(phrase, out_type=str, enable_sampling=True, alpha=0.1, nbest_size=-1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PYko19NiKdtK"
   },
   "source": [
    "## Tokenizer insights\n",
    "It is pretty evident that there is a lot of flexibility in how we can represent words (and word sequences) with a BPE-based Tokenizer!\n",
    "\n",
    "As mentioned before, we are not training any model in this Tutorial. Nevertheless, we want to share some key insights regarding the training scripts that you might want to know.\n",
    "\n",
    "First, we need a hyperparameters YAML file: \n",
    "- Hyperparameter file: `tokenizer.yaml`:\n",
    "\n",
    "```yaml\n",
    "# ############################################################################\n",
    "# Tokenizer: subword BPE with unigram 5K\n",
    "# Training: Librispeech 960h\n",
    "# Authors:  Abdel Heba 2021\n",
    "# ############################################################################\n",
    "\n",
    "output_folder: !ref results/5K_subword_unigram_960h_LM/\n",
    "train_log: !ref <output_folder>/train_log.txt\n",
    "\n",
    "# Data files\n",
    "data_folder: !PLACEHOLDER # e.g., /path/to/LibriSpeech\n",
    "train_splits: [\"train-clean-100\", \"train-clean-360\", \"train-other-500\"]\n",
    "dev_splits: [\"dev-clean\"]\n",
    "test_splits: [\"test-clean\", \"test-other\"]\n",
    "train_csv: !ref <output_folder>/train.csv\n",
    "valid_csv: !ref <output_folder>/dev-clean.csv\n",
    "\n",
    "# Training parameters\n",
    "token_type: unigram  # [\"unigram\", \"bpe\", \"char\"]\n",
    "token_output: 5000  # index(blank/eos/bos/unk) = 0\n",
    "character_coverage: 1.0\n",
    "csv_read: words\n",
    "bos_index: 1 # Begining of sentence index\n",
    "eos_index: 2 # End of sentence index\n",
    "\n",
    "\n",
    "tokenizer: !name:speechbrain.tokenizers.SentencePiece.SentencePiece\n",
    "   model_dir: !ref <output_folder>\n",
    "   vocab_size: !ref <token_output>\n",
    "   annotation_train: !ref <train_csv>\n",
    "   annotation_read: wrd\n",
    "   model_type: \"unigram\" # [\"unigram\", \"bpe\", \"char\"]\n",
    "   character_coverage: 1.0\n",
    "   bos_id: !ref <bos_index> # Define bos_id/eos_id if different from blank_id\n",
    "   eos_id: !ref <eos_index>\n",
    "   annotation_list_to_check: [!ref <train_csv>, !ref <valid_csv>]\n",
    "```\n",
    "\n",
    "The training script will take the item() 'words' from each training sample of the JSON file and train the Tokenizer:\n",
    "\n",
    "```json\n",
    "{\n",
    "  \"1867-154075-0032\": {\n",
    "    \"wav\": \"{data_root}/LibriSpeech/train-clean-5/1867/154075/1867-154075-0032.flac\",\n",
    "    \"length\": 16.09,\n",
    "    \"words\": \"AND HE BRUSHED A HAND ACROSS HIS FOREHEAD AND WAS INSTANTLY HIMSELF CALM AND COOL VERY WELL THEN IT SEEMS I'VE MADE AN ASS OF MYSELF BUT I'LL TRY TO MAKE UP FOR IT NOW WHAT ABOUT CAROLINE\"\n",
    "  },...,\n",
    "    n_samples\n",
    "}\n",
    "```\n",
    "\n",
    "The tokenizer is trained on training annotation only. We set here a vocabulary size of 5000. Instead of using the standard BPE algorithm, we use a variation of it based on unigram smoothing. See [sentencepiece](https://github.com/google/sentencepiece) for more info.\n",
    "The tokenizer will be saved in the specified `output_folder`. \n",
    "\n",
    "- Training script: `train.py`:\n",
    "\n",
    "Essentially, we prepare the data with the `prepare_mini_librispeech` script and we then run the sentencepiece tokenizer wrapped in the class:\n",
    "!name:`speechbrain.tokenizers.SentencePiece.SentencePiece`.\n",
    "\n",
    "\n",
    "### Output files\n",
    "The Tokenizer script will generate a binary file containing all the information needed for tokenizing an input text and a file reporting the model's list of tokens and their log probabilities\n",
    "+ *5000_unigram.model*\n",
    "+ *5000_unigram.vocab*\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nkYENC7BJ4K9"
   },
   "source": [
    "## **Step 2: Language Model**\n",
    "A Language Model (LM) can be used within a speech recognizer in different ways. In this tutorial, we perform the so-called **shallow fusion** where the language information is used within the beam searcher of the speech recognizer to rescore the partial hypothesis. In practice, for every time step, we rescore the partial hypothesis provided by the speech recognizer with the language scores (that penalize sequences of tokens that are \"unlikely\" to be observed).\n",
    "\n",
    "The following image gives more details about shallow fusion:\n",
    "\n",
    "<img src=\"Figures/shallow_fusion.png\">\n",
    "\n",
    "**Shallow fusion of LM + ASR**\n",
    "\n",
    "\n",
    "Some recent studies have shown that a speech recognizer trained on a very large dataset can achieve impressive performance even without a language. However, for medium-scale speech recognition tasks like Librispeech 1000h, the language model still plays a role in improving the final performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Basic information about our ASR model**\n",
    "\n",
    "As explained before, the speechbrain ASR system fetched from Huggingface is composed of three main elements: \n",
    "+ Tokenizer\n",
    "+ Language Model\n",
    "+ Acoustic Model \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our system has the following modules: odict_keys(['compute_features', 'pre_transformer', 'transformer', 'asr_model', 'normalize', 'lm_model', 'encoder', 'decoder'])\n"
     ]
    }
   ],
   "source": [
    "# Let's get some information from our LM\n",
    "# we can access the modules of the ASR class with `.modules.`\n",
    "\n",
    "# Get the model in `asr_model`\n",
    "asr_model = EncoderDecoderASR.from_hparams(source=\"speechbrain/asr-transformer-transformerlm-librispeech\", savedir=\"pretrained_models/\")\n",
    "print(\"Our system has the following modules: {}\".format(asr_model.modules.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Language Model has a embedding dimension of: 768\n",
      "The Language Model has 12 encoder layers\n",
      "The Language Model has 93M parameters\n"
     ]
    }
   ],
   "source": [
    "dim_embedding = asr_model.modules.lm_model.__dict__['d_embedding']\n",
    "num_encoder_layers = asr_model.modules.lm_model.__dict__['num_encoder_layers']\n",
    "params_lm = int(sum(p.numel() for p in asr_model.modules.lm_model.parameters()))\n",
    "\n",
    "print(f\"The Language Model has a embedding dimension of: {dim_embedding}\")\n",
    "print(f\"The Language Model has {num_encoder_layers} encoder layers\")\n",
    "print(f\"The Language Model has {int(params_lm/1e6)}M parameters\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Encoder has 153M parameters\n",
      "The ASR model has 161M parameters\n",
      "The remaining 8M parameters are in the output/normalization/FrontEnd layers\n",
      "\n",
      "---Decoder = ASR model + LM model---\n",
      "The Decoder has 254M parameters\n"
     ]
    }
   ],
   "source": [
    "asr_model.modules.transformer.__dict__['_parameters']\n",
    "params_asr_model = int(sum(p.numel() for p in asr_model.modules.asr_model.parameters()))\n",
    "params_encoder = int(sum(p.numel() for p in asr_model.modules.encoder.parameters()))\n",
    "params_decoder = int(sum(p.numel() for p in asr_model.modules.decoder.parameters()))\n",
    "\n",
    "print(f\"The Encoder has {int(params_encoder/1e6)}M parameters\")\n",
    "print(f\"The ASR model has {int(params_asr_model/1e6)}M parameters\")\n",
    "print(f\"The remaining {int(params_asr_model/1e6) - int(params_encoder/1e6)}M parameters are in the output/normalization/FrontEnd layers\")\n",
    "print(f\"\\n---Decoder = ASR model + LM model---\")\n",
    "print(f\"The Decoder has {int(params_decoder/1e6)}M parameters\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "b3tnXnrWc2My"
   },
   "source": [
    "## Training a LM\n",
    "\n",
    "When you train a LM (next commands) some files/folders are generated in the specified `output_folder` from the `hparams/transformer.yaml`\n",
    "\n",
    "```\n",
    "pip install datasets\n",
    "cd NLP_Summer_School-2021_Speech_Tutorial/ASR/LibriSpeech/LM\n",
    "python train.py hparams/transformer.yaml\n",
    "```\n",
    "\n",
    "Such as: \n",
    "\n",
    "*   `train_log.txt`: contains the statistics (e.g, train_loss, valid_loss) computed at each epoch. \n",
    "*   `log.txt`: is a more detailed logger containing the timestamps for each basic operation.\n",
    "*  `env.log`: shows all the dependencies used with their corresponding version (useful for replicability).\n",
    "\n",
    "*  `train.py`, `hyperparams.yaml`:  are a copy of the experiment file along with the corresponding hyperparameters (for replicability).\n",
    "\n",
    "* `save`:  is the place where we store the learned model.\n",
    "\n",
    "In the `save` folder:\n",
    "+ Subfolders containing the checkpoints saved during training (in the format `CKPT+data+time`),\n",
    "+ Normally: two checkpoints - the best (i.e, the oldest one) and the latest (i.e, the most recent one).\n",
    "\n",
    "Inside each checkpoint, you can find all the information needed to resume training (e.g, models, optimizers, schedulers, epoch counter, etc.). The parameters of the transformer model are reported in `model.ckpt` file. This is just a binary format readable with `torch.load`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mnCM5xuy85P4"
   },
   "source": [
    "### **Experiment file**\n",
    "Let's now take a look into how the objects, functions, and hyperparameters declared in the yaml file are used in `train.py` to implement the language model.\n",
    "\n",
    "\n",
    "```python\n",
    "# Recipe begins!\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    # Reading command line arguments\n",
    "    hparams_file, run_opts, overrides = sb.parse_arguments(sys.argv[1:])\n",
    "\n",
    "    # Initialize ddp (useful only for multi-GPU DDP training)\n",
    "    sb.utils.distributed.ddp_init_group(run_opts)\n",
    "\n",
    "    # Load hyperparameters file with command-line overrides\n",
    "    with open(hparams_file) as fin:\n",
    "        hparams = load_hyperpyyaml(fin, overrides)\n",
    "\n",
    "    # Create experiment directory\n",
    "    sb.create_experiment_directory(\n",
    "        experiment_directory=hparams[\"output_folder\"],\n",
    "        hyperparams_to_save=hparams_file,\n",
    "        overrides=overrides,\n",
    "    )\n",
    "```\n",
    "\n",
    "We here do some preliminary operations such as:\n",
    "+ Parsing the command line,\n",
    "+ Initializing the distributed data-parallel (needed if multiple GPUs are used),\n",
    "+ Creating the output folder and, \n",
    "+ Reading the configuration file (YAML format).\n",
    "\n",
    "```python\n",
    "    # Initialize the Brain object to prepare for LM training.\n",
    "    lm_brain = LM(\n",
    "        modules=hparams[\"modules\"],\n",
    "        opt_class=hparams[\"optimizer\"],\n",
    "        hparams=hparams,\n",
    "        run_opts=run_opts,\n",
    "        checkpointer=hparams[\"checkpointer\"],\n",
    "    )\n",
    "```\n",
    "The brain class implements all the functionalities needed for supporting the training and validation loops.  Its `fit` and `evaluate` methods perform training and test, respectively:\n",
    "\n",
    "```python\n",
    "    lm_brain.fit(\n",
    "        lm_brain.hparams.epoch_counter,\n",
    "        train_data,\n",
    "        valid_data,\n",
    "        train_loader_kwargs=hparams[\"train_dataloader_opts\"],\n",
    "        valid_loader_kwargs=hparams[\"valid_dataloader_opts\"],\n",
    "    )\n",
    "\n",
    "    # Load best checkpoint for evaluation\n",
    "    test_stats = lm_brain.evaluate(\n",
    "        test_data,\n",
    "        min_key=\"loss\",\n",
    "        test_loader_kwargs=hparams[\"test_dataloader_opts\"],\n",
    "    )\n",
    "```\n",
    "The training and validation data loaders are given in input to the fit method, while the test dataset is fed into the evaluate method.\n",
    "\n",
    "## Key methods in the Brain class\n",
    "\n",
    "#### **1. Forward Computations**\n",
    "\n",
    "Defines all the computations needed to transform the input text into the output predictions.\n",
    "\n",
    "What we do here? \n",
    "+ Put the batch on the right device (CPU/GPU),\n",
    "+ Forward pass: encoded tokens --> model --> output predictions\n",
    "\n",
    "<img src=\"Figures/forward_pass.png\" width=\"400\">\n",
    "\n",
    "**Forward/backward pass in a network with fully connected layers**\n",
    "\n",
    "\n",
    "#### **2. Compute Objectives**\n",
    "\n",
    "Takes the targets, the predictions, and estimates a loss function:\n",
    "\n",
    "How? \n",
    "+ Get predictions from Forward pass\n",
    "+ Compute the loss function: compare predictions with target tokens\n",
    "\n",
    "<img src=\"Figures/loss_function.png\" width=\"400\">\n",
    "\n",
    "**How to compute the loss function between predictions and ground truth labels**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tFJ34alleSBH"
   },
   "source": [
    "## **Step 4: Speech Recognizer**\n",
    "At this point, we can train our speech recognizer. In this tutorial, we are\n",
    "going to train an **attention-based end-to-end speech recognizer** (offline).\n",
    "The encoder relies on a combination of convolutional, recurrent, and fully connected models. The decoder is an autoregressive GRU decoder. An attention mechanism is employed between encoding and decoder. The final sequence of words is retrieved with beamsearch coupled with the RNNLM trained in the previous step. \n",
    "The attention-based system is jointly trained with CTC (applied on the top of the encoder).\n",
    "The system uses data augmentation techniques to improve its performance.\n",
    "\n",
    "### **Train the speech recognizer**\n",
    "To train the speech recognizer, run the following code:\n",
    "\n",
    "<img src=\"Figures/end-to-end.png\" width=\"500\">\n",
    "\n",
    "**Standard end-to-end system trained with CTC+Attention loss**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dfHa8TQMYUle"
   },
   "source": [
    "### **Hyperparameters**\n",
    "\n",
    "\n",
    "The hyperparameter file starts with the definition of basic things, such as seed and path settings:\n",
    "\n",
    "#### **Data related**\n",
    "\n",
    "```yaml\n",
    "# Seed needs to be set at top of yaml, before objects with parameters are instantiated\n",
    "seed: 2602\n",
    "__set_seed: !apply:torch.manual_seed [!ref <seed>]\n",
    "\n",
    "data_folder: ../data # In this case, data will be automatically downloaded here.\n",
    "data_folder_rirs: !ref <data_folder> # noise/ris dataset will automatically be downloaded here\n",
    "output_folder: !ref results/CRDNN_BPE_960h_LM/<seed>\n",
    "wer_file: !ref <output_folder>/wer.txt\n",
    "save_folder: !ref <output_folder>/save\n",
    "train_log: !ref <output_folder>/train_log.txt\n",
    "\n",
    "pretrained_path: speechbrain/asr-crdnn-rnnlm-librispeech\n",
    "\n",
    "# Path where data manifest files will be stored. The data manifest files are created by the\n",
    "# data preparation script\n",
    "train_annotation: ../train.json\n",
    "valid_annotation: ../valid.json\n",
    "test_annotation: ../test.json\n",
    "\n",
    "# The train logger writes training statistics to a file, as well as stdout.\n",
    "train_logger: !new:speechbrain.utils.train_logger.FileTrainLogger\n",
    "    save_file: !ref <train_log>\n",
    "```\n",
    "\n",
    "The `data_folder` corresponds to the path where the mini-librispeech is stored. \n",
    "\n",
    "We also have to specify the data manifest files for training, validation, and test. If not available, these files will be created by the data preparation script called in `train.py`.\n",
    "\n",
    "After that, we define a bunch of parameters for training, feature extraction, model definition, and decoding:\n",
    "\n",
    "#### **Model related**\n",
    "\n",
    "```yaml\n",
    "# Training parameters\n",
    "number_of_epochs: 15\n",
    "number_of_ctc_epochs: 5\n",
    "batch_size: 8\n",
    "lr: 1.0\n",
    "ctc_weight: 0.5\n",
    "sorting: ascending\n",
    "ckpt_interval_minutes: 15 # save checkpoint every N min\n",
    "label_smoothing: 0.1\n",
    "\n",
    "# Model parameters\n",
    "activation: !name:torch.nn.LeakyReLU\n",
    "dropout: 0.15\n",
    "cnn_blocks: 2\n",
    "cnn_channels: (128, 256)\n",
    "inter_layer_pooling_size: (2, 2)\n",
    "cnn_kernelsize: (3, 3)\n",
    "time_pooling_size: 4\n",
    "rnn_class: !name:speechbrain.nnet.RNN.LSTM\n",
    "rnn_layers: 4\n",
    "rnn_neurons: 1024\n",
    "rnn_bidirectional: True\n",
    "dnn_blocks: 2\n",
    "dnn_neurons: 512\n",
    "emb_size: 128\n",
    "dec_neurons: 1024\n",
    "output_neurons: 1000  # Number of tokens (same as LM)\n",
    "blank_index: 0\n",
    "bos_index: 0\n",
    "eos_index: 0\n",
    "unk_index: 0\n",
    "```\n",
    "\n",
    "For instance, we define the number of epochs, the initial learning rate, the batch size, the weight of the CTC loss, and many others. \n",
    "\n",
    "We can also add: \n",
    "\n",
    "+ Different feature extraction 'layers' (FBANK, MFCC, or wav2vec)\n",
    "+ Normalization layer\n",
    "+ Environmental corruption\n",
    "+ Data augmentation for Speech --> SpecAugment, Speed Perturbation, etc\n",
    "+ Beam search algorithm + hyperparams\n",
    "\n",
    "\n",
    "```yaml\n",
    "# This object is used to pretrain the language model and the tokenizers\n",
    "# (defined above). In this case, we also pretrain the ASR model (to make\n",
    "# sure the model converges on a small amount of data)\n",
    "pretrainer: !new:speechbrain.utils.parameter_transfer.Pretrainer\n",
    "    collect_in: !ref <save_folder>\n",
    "    loadables:\n",
    "        lm: !ref <lm_model>\n",
    "        tokenizer: !ref <tokenizer>\n",
    "        model: !ref <model>\n",
    "    paths:\n",
    "        lm: !ref <pretrained_path>/lm.ckpt\n",
    "        tokenizer: !ref <pretrained_path>/tokenizer.ckpt\n",
    "        model: !ref <pretrained_path>/asr.ckpt\n",
    "\n",
    "```\n",
    " Additionally, we can add pre-trained models such as L:M\n",
    "The final object is the pretrainer that links the language model, the tokenizer, and the acoustic speech recognition model with their corresponding files used for pre-training.  We here pre-train the acoustic model as well. One such a small dataset, it is very hard to make an end-to-end speech recognizer converging and we thus use another model to pre-trained it (you should skip this part when training on a larger dataset)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **What about inference and outputs?**\n",
    "\n",
    "Performing ASR inference in a bunch of wav files would provide a detailed report such as: \n",
    "\n",
    "\n",
    "```\n",
    "%WER 3.09 [ 1622 / 52576, 167 ins, 171 del, 1284 sub ]\n",
    "%SER 33.66 [ 882 / 2620 ]\n",
    "Scored 2620 sentences, 0 not present in hyp.\n",
    "================================================================================\n",
    "ALIGNMENTS\n",
    "\n",
    "Format:\n",
    "<utterance-id>, WER DETAILS\n",
    "<eps> ; reference  ; on ; the ; first ;  line\n",
    "  I   ;     S      ; =  ;  =  ;   S   ;   D  \n",
    " and  ; hypothesis ; on ; the ; third ; <eps>\n",
    "================================================================================\n",
    "672-122797-0033, %WER 0.00 [ 0 / 2, 0 ins, 0 del, 0 sub ]\n",
    "A ; STORY\n",
    "= ;   =  \n",
    "A ; STORY\n",
    "================================================================================\n",
    "2094-142345-0041, %WER 0.00 [ 0 / 1, 0 ins, 0 del, 0 sub ]\n",
    "DIRECTION\n",
    "    =    \n",
    "DIRECTION\n",
    "================================================================================\n",
    "2830-3980-0026, %WER 50.00 [ 1 / 2, 0 ins, 0 del, 1 sub ]\n",
    "VERSE ; TWO\n",
    "  S   ;  = \n",
    "FIRST ; TWO\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4LnRq1_cpPXZ"
   },
   "source": [
    "## **Step 5: Inference**\n",
    "\n",
    "At this point, we can use the trained speech recognizer. For this type of ASR model, speechbrain made available some classes ([take a look here](https://github.com/speechbrainspeechbrain/blob/develop/speechbrain/pretrained/interfaces.py)) such as the `EncoderDecoderASR` one that can make inference easier. For instance, we can transcribe an audio file with a pre-trained model hosted in our [HuggingFace repository](https://huggingface.co/speechbrain) in solely 4 lines of code:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 197,
     "referenced_widgets": [
      "793ef14b7b004096981c55e7bf4fbdae",
      "c8edc1eae8084ade9b3e02be21ac6b36",
      "ba5f07c308fa42f0963848266d7e376d",
      "742aaf25ce0b4911ad1b17aced2a411f",
      "5a908cae48844f8ca14baf189d7e58bd",
      "676c443474a64391bb0398cfd3b7d7c5",
      "8d8f39950d0d416395d3c1c2afc03396",
      "1d871e41a1c346c0941ff8bf286a8fc2",
      "2b38891bfbf148c99c8f770a46c129dd",
      "772373f931bc42869027b4db253737ad",
      "1060fe2ec0774468a5903acb2b7f9a87",
      "6248b94de0464c2b933add8e4f6b7af4",
      "48901abf068b4242a014050db20b0631",
      "eff25baa67674ee58e9715e78cd5b7a1",
      "f917b17d56734fb1b8cb471e51b15328",
      "2a8a07ff265941c78d3dd4915f5c11a1",
      "31a565eb19ab4091a965a1191a0f9e65",
      "1b9fd09c88184811ad52d2b03c60422d",
      "32f78deb548546a788a92d9507f6eb72",
      "e239d2cbb12346ffb706cacab4dca38a",
      "209d0ef110b343d08759c8daeaeb78b8",
      "19800374b3cc44db9c82637d3981265a",
      "16fd875c6034418d844de3aa5f18d8d9",
      "1247b9b12f884d00b318569af5d1c33f",
      "2569d3526a6742828af2d9360a67d312",
      "472f38e4f2514fcca5840a19bd6b80c7",
      "cf48aa6b98014f97a974ca398287b6a4",
      "07aadeb0ed4c4fc7a9ea91b3938a2e02",
      "afa3cd14810244bf92d8814bd695f3b6",
      "69bcb272473c45caac52ac93725ab4e1",
      "cb36b99b7ee24cefa46590ecc0122b72",
      "26573bd508184e5faac952104b8784b5",
      "2e7f8ea4c64d49478573974925975f18",
      "2b7c662594354cfa9327ba21f93fe51e",
      "b5ad90b6a6924ae3993ff2a9751c917c",
      "3af10f6cc57a47719bfca37ee59eb84f",
      "b176842c64324374b0d42325dbdae328",
      "55e848a9b4264094b5e9fa9e29adf605",
      "326aecdc3b3342ceb3d0bb82c1b6ca93",
      "855230c0c2fd46fcb28a63065ce5ebd7",
      "cc771ea227a94bcf9ffda70f5085f90f",
      "81573628e9ef4ec18a325a0d62b790e8",
      "c5cd1cec1745490aa00041eaccf3f4e3",
      "03842889ca4f42ddabecf025fa71cfd1",
      "9e8b3e216161422bb18c494ee3da756d",
      "4377bcef40f142efaa448b925d36730f",
      "2e96792c1c3949ef9deb839df5c3f8e9",
      "20d770de4aa74489a9f816cf038809b4",
      "34181d8ec5fa45fe858b56c3eb86aed6",
      "f207a275c2624be9b89d74b2f0fe2738",
      "418580459dc54712a947fbdf6ec8bd37",
      "d7887ea69bfe4ffa931d1a730d0e9e02",
      "e3fecdd0618745928f6d778aebc05afa",
      "5ccec8b8ad064037bf7f55ebb9e23907",
      "3f9828cfafc14ee9935039fd43f4c6a0"
     ]
    },
    "id": "uvvY0dCbx5Sv",
    "outputId": "bd7f3294-25f4-486a-de35-acdb5d0382c4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "THE BIRCH CANOE SLID ON THE SMOOTH PLANKS\n"
     ]
    }
   ],
   "source": [
    "from speechbrain.pretrained import EncoderDecoderASR\n",
    "\n",
    "asr_model = EncoderDecoderASR.from_hparams(source=\"speechbrain/asr-transformer-transformerlm-librispeech\", savedir=\"pretrained_models/\")\n",
    "audio_file = \"pretrained_models/example.wav\"\n",
    "transcript = asr_model.transcribe_file(audio_file)\n",
    "\n",
    "print(transcript)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "z3pu0M42Pqju"
   },
   "source": [
    "## **Customize your speech recognizer**\n",
    "In a general case, you might have your own data and you would like to use your own model. Let's comment a bit more on how you can customize your recipe. \n",
    "\n",
    "**Suggestion**:  start from a recipe that is working (like the one used for this template) and only do the minimal modifications needed to customize it. Test your model step by step. Make sure your model can overfit on a tiny dataset composed of few sentences. If it doesn't overfit there is likely a bug in your model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "W4pPJ0k3lJZj"
   },
   "source": [
    "## **Conclusion**\n",
    "\n",
    "In this short tutorial, we reviewed the main parts for building an ASR system (e.g. Tokenizer, Language Model and Acoustic Model) with Speechbrain. Additionally, we learned how to use the `EncoderDecoderASR` interface which allows you to perform speech recognition with less than 4 lines of code! \n",
    "\n",
    "Special thanks to the [Speechbrain](https://github.com/speechbrain/speechbrain) team and [Huggingface](https://github.com/huggingface/transformers)!\n",
    "\n",
    "\n",
    "Here are some recipes developed in Speechbrain:\n",
    "\n",
    "- [LibriSpeech recipes](https://github.com/speechbrain/speechbrain/tree/develop/recipes/LibriSpeech)\n",
    "- [CommonVoice](https://github.com/speechbrain/speechbrain/tree/develop/recipes/CommonVoice)\n",
    "- [AISHELL-1](https://github.com/speechbrain/speechbrain/tree/develop/recipes/AISHELL-1)\n",
    "- [TIMIT](https://github.com/speechbrain/speechbrain/tree/develop/recipes/TIMIT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "P-Trg_abjUTd"
   },
   "source": [
    "## Related Tutorials\n",
    "\n",
    "These are some related tutorials if you want to further explore the ASR field:\n",
    "\n",
    "0. [ASRfromScratch](https://colab.research.google.com/drive/1aFgzrUv3udM_gNJNUoLaHIm78QHtxdIz?usp=sharing)\n",
    "1. [YAML hyperpatameter specification](https://colab.research.google.com/drive/1Pg9by4b6-8QD2iC0U7Ic3Vxq4GEwEdDz?usp=sharing)\n",
    "2. [Brain Class](https://colab.research.google.com/drive/1fdqTk4CTXNcrcSVFvaOKzRfLmj4fJfwa?usp=sharing)\n",
    "3. [Checkpointing](https://colab.research.google.com/drive/1VH7U0oP3CZsUNtChJT2ewbV_q1QX8xre?usp=sharing)\n",
    "4. [Data-io](https://colab.research.google.com/drive/1AiVJZhZKwEI4nFGANKXEe-ffZFfvXKwH?usp=sharing)\n",
    "5. [Tokenizer](https://colab.research.google.com/drive/12yE3myHSH-eUxzNM0-FLtEOhzdQoLYWe?usp=sharing)\n",
    "6. [Speech Features](https://colab.research.google.com/drive/1CI72Xyay80mmmagfLaIIeRoDgswWHT_g?usp=sharing)\n",
    "7. [Speech Augmentation](https://colab.research.google.com/drive/1JJc4tBhHNXRSDM2xbQ3Z0jdDQUw4S5lr?usp=sharing)\n",
    "8. [Environmental Corruption](https://colab.research.google.com/drive/1mAimqZndq0BwQj63VcDTr6_uCMC6i6Un?usp=sharing)\n",
    "9. [MultiGPU Training](https://colab.research.google.com/drive/13pBUacPiotw1IvyffvGZ-HrtBr9T6l15?usp=sharing)\n",
    "10. [Pretrain and Fine-tune](https://colab.research.google.com/drive/1LN7R3U3xneDgDRK2gC5MzGkLysCWxuC3?usp=sharing)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Copy of ASRfromScratch.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "03842889ca4f42ddabecf025fa71cfd1": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "07aadeb0ed4c4fc7a9ea91b3938a2e02": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "1060fe2ec0774468a5903acb2b7f9a87": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "1247b9b12f884d00b318569af5d1c33f": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "16fd875c6034418d844de3aa5f18d8d9": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_2569d3526a6742828af2d9360a67d312",
       "IPY_MODEL_472f38e4f2514fcca5840a19bd6b80c7",
       "IPY_MODEL_cf48aa6b98014f97a974ca398287b6a4"
      ],
      "layout": "IPY_MODEL_1247b9b12f884d00b318569af5d1c33f"
     }
    },
    "19800374b3cc44db9c82637d3981265a": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "1b9fd09c88184811ad52d2b03c60422d": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "1d871e41a1c346c0941ff8bf286a8fc2": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "209d0ef110b343d08759c8daeaeb78b8": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "20d770de4aa74489a9f816cf038809b4": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_e3fecdd0618745928f6d778aebc05afa",
      "max": 104390,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_d7887ea69bfe4ffa931d1a730d0e9e02",
      "value": 104390
     }
    },
    "2569d3526a6742828af2d9360a67d312": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_afa3cd14810244bf92d8814bd695f3b6",
      "placeholder": "​",
      "style": "IPY_MODEL_07aadeb0ed4c4fc7a9ea91b3938a2e02",
      "value": "Downloading: 100%"
     }
    },
    "26573bd508184e5faac952104b8784b5": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "2a8a07ff265941c78d3dd4915f5c11a1": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_19800374b3cc44db9c82637d3981265a",
      "placeholder": "​",
      "style": "IPY_MODEL_209d0ef110b343d08759c8daeaeb78b8",
      "value": " 480M/480M [00:08&lt;00:00, 55.6MB/s]"
     }
    },
    "2b38891bfbf148c99c8f770a46c129dd": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "2b7c662594354cfa9327ba21f93fe51e": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_3af10f6cc57a47719bfca37ee59eb84f",
       "IPY_MODEL_b176842c64324374b0d42325dbdae328",
       "IPY_MODEL_55e848a9b4264094b5e9fa9e29adf605"
      ],
      "layout": "IPY_MODEL_b5ad90b6a6924ae3993ff2a9751c917c"
     }
    },
    "2e7f8ea4c64d49478573974925975f18": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "2e96792c1c3949ef9deb839df5c3f8e9": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_418580459dc54712a947fbdf6ec8bd37",
      "placeholder": "​",
      "style": "IPY_MODEL_f207a275c2624be9b89d74b2f0fe2738",
      "value": "Downloading: 100%"
     }
    },
    "31a565eb19ab4091a965a1191a0f9e65": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "326aecdc3b3342ceb3d0bb82c1b6ca93": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "32f78deb548546a788a92d9507f6eb72": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "34181d8ec5fa45fe858b56c3eb86aed6": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_3f9828cfafc14ee9935039fd43f4c6a0",
      "placeholder": "​",
      "style": "IPY_MODEL_5ccec8b8ad064037bf7f55ebb9e23907",
      "value": " 104k/104k [00:00&lt;00:00, 297kB/s]"
     }
    },
    "3af10f6cc57a47719bfca37ee59eb84f": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_855230c0c2fd46fcb28a63065ce5ebd7",
      "placeholder": "​",
      "style": "IPY_MODEL_326aecdc3b3342ceb3d0bb82c1b6ca93",
      "value": "Downloading: 100%"
     }
    },
    "3f9828cfafc14ee9935039fd43f4c6a0": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "418580459dc54712a947fbdf6ec8bd37": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "4377bcef40f142efaa448b925d36730f": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "472f38e4f2514fcca5840a19bd6b80c7": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_cb36b99b7ee24cefa46590ecc0122b72",
      "max": 212420087,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_69bcb272473c45caac52ac93725ab4e1",
      "value": 212420087
     }
    },
    "48901abf068b4242a014050db20b0631": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "55e848a9b4264094b5e9fa9e29adf605": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_03842889ca4f42ddabecf025fa71cfd1",
      "placeholder": "​",
      "style": "IPY_MODEL_c5cd1cec1745490aa00041eaccf3f4e3",
      "value": " 253k/253k [00:00&lt;00:00, 3.82MB/s]"
     }
    },
    "5a908cae48844f8ca14baf189d7e58bd": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_1060fe2ec0774468a5903acb2b7f9a87",
      "placeholder": "​",
      "style": "IPY_MODEL_772373f931bc42869027b4db253737ad",
      "value": " 4.42k/4.42k [00:00&lt;00:00, 80.0kB/s]"
     }
    },
    "5ccec8b8ad064037bf7f55ebb9e23907": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "6248b94de0464c2b933add8e4f6b7af4": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_eff25baa67674ee58e9715e78cd5b7a1",
       "IPY_MODEL_f917b17d56734fb1b8cb471e51b15328",
       "IPY_MODEL_2a8a07ff265941c78d3dd4915f5c11a1"
      ],
      "layout": "IPY_MODEL_48901abf068b4242a014050db20b0631"
     }
    },
    "676c443474a64391bb0398cfd3b7d7c5": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "69bcb272473c45caac52ac93725ab4e1": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "742aaf25ce0b4911ad1b17aced2a411f": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_2b38891bfbf148c99c8f770a46c129dd",
      "max": 4420,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_1d871e41a1c346c0941ff8bf286a8fc2",
      "value": 4420
     }
    },
    "772373f931bc42869027b4db253737ad": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "793ef14b7b004096981c55e7bf4fbdae": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_ba5f07c308fa42f0963848266d7e376d",
       "IPY_MODEL_742aaf25ce0b4911ad1b17aced2a411f",
       "IPY_MODEL_5a908cae48844f8ca14baf189d7e58bd"
      ],
      "layout": "IPY_MODEL_c8edc1eae8084ade9b3e02be21ac6b36"
     }
    },
    "81573628e9ef4ec18a325a0d62b790e8": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "855230c0c2fd46fcb28a63065ce5ebd7": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "8d8f39950d0d416395d3c1c2afc03396": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "9e8b3e216161422bb18c494ee3da756d": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_2e96792c1c3949ef9deb839df5c3f8e9",
       "IPY_MODEL_20d770de4aa74489a9f816cf038809b4",
       "IPY_MODEL_34181d8ec5fa45fe858b56c3eb86aed6"
      ],
      "layout": "IPY_MODEL_4377bcef40f142efaa448b925d36730f"
     }
    },
    "afa3cd14810244bf92d8814bd695f3b6": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b176842c64324374b0d42325dbdae328": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_81573628e9ef4ec18a325a0d62b790e8",
      "max": 253217,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_cc771ea227a94bcf9ffda70f5085f90f",
      "value": 253217
     }
    },
    "b5ad90b6a6924ae3993ff2a9751c917c": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ba5f07c308fa42f0963848266d7e376d": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_8d8f39950d0d416395d3c1c2afc03396",
      "placeholder": "​",
      "style": "IPY_MODEL_676c443474a64391bb0398cfd3b7d7c5",
      "value": "Downloading: 100%"
     }
    },
    "c5cd1cec1745490aa00041eaccf3f4e3": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "c8edc1eae8084ade9b3e02be21ac6b36": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "cb36b99b7ee24cefa46590ecc0122b72": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "cc771ea227a94bcf9ffda70f5085f90f": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "cf48aa6b98014f97a974ca398287b6a4": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_2e7f8ea4c64d49478573974925975f18",
      "placeholder": "​",
      "style": "IPY_MODEL_26573bd508184e5faac952104b8784b5",
      "value": " 212M/212M [00:04&lt;00:00, 51.5MB/s]"
     }
    },
    "d7887ea69bfe4ffa931d1a730d0e9e02": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "e239d2cbb12346ffb706cacab4dca38a": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e3fecdd0618745928f6d778aebc05afa": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "eff25baa67674ee58e9715e78cd5b7a1": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_1b9fd09c88184811ad52d2b03c60422d",
      "placeholder": "​",
      "style": "IPY_MODEL_31a565eb19ab4091a965a1191a0f9e65",
      "value": "Downloading: 100%"
     }
    },
    "f207a275c2624be9b89d74b2f0fe2738": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "f917b17d56734fb1b8cb471e51b15328": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_e239d2cbb12346ffb706cacab4dca38a",
      "max": 479555971,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_32f78deb548546a788a92d9507f6eb72",
      "value": 479555971
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
