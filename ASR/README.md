## Please follow these instructions before opening the ASR Notebook

Here, we train an automatic speech recognition system with the SpeechBrain toolkit. The pre-trained models are trained with LibrSpeech 960h train-set. The LM is further enriched with an additonal 1.5GB of text data. Original LibriSpeech recipe --> [here](https://github.com/speechbrain/speechbrain/tree/develop/recipes/LibriSpeech)

### Pretrained models - NLP summer school

For the sake of simplicity we provide pre-trained models from Huggingface, for Acoustic & Language Model and Tokenizer, download them beforehand. We are using the best model for LibriSpeech from huggingface:
- [Transformer + ctc + TransformerLM](https://huggingface.co/speechbrain/asr-transformer-transformerlm-librispeech)

### Train your own automatic speech recognizer from scratch 

To train a full speech recognition system the pipeline is the following:
1. **Train a tokenizer.** The tokenizer takes in input the training transcripts and determines the subword units that will be used for both acoustic and language model training. **Training a tokenizer before the language and acoustic model is necessary**. Indeed, both of them will reuse this tokenizer to map the output tokens.
2. **Train a Language Model (LM).** The language model takes in input long texts from available books. We have recipes with RNN and transformer-based LMs. In both cases, the LM is used during beam search to assign different weights to different hypotheses generated by the acoustic model.
3. **Train an acoustic model (AM).** The acoustic model maps the input speech into a set of sub-words units. The current repository contains recipes for seq2seq (ctc+attention), transducers, and transformer-based systems. Since training an LM can take several days, by default the recipes downloads a pre-trained LM.

## How to simply use pretrained models to transcribe my audio file?

SpeechBrain provides a simple interface to transcribe audio files with pretrained models. All the necessary information can be found on the different HuggingFace repositories corresponding to our different models for LibriSpeech:
- [seq2seq (ctc+attention) + RNNLM](https://huggingface.co/speechbrain/asr-crdnn-rnnlm-librispeech)
- [seq2seq (ctc+attention) + TransformerLM](https://huggingface.co/speechbrain/asr-crdnn-transformerlm-librispeech)
- [Transformer + ctc + TransformerLM](https://huggingface.co/speechbrain/asr-transformer-transformerlm-librispeech)

### Pretrained models + further training 

To fine-tune the pre-trained models, you need to first download them and modify accordingly the training YAML configuration files; such as: `ASR/LibriSpeech/ASR/transformer/hparams/transformer.yaml`
